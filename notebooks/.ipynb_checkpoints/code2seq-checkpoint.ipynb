{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5OLd1AL5gIQw"
   },
   "source": [
    "# A PyTorch re-implementation code for \"code2seq: Generating Sequences from Structured Representations of Code\"\n",
    "\n",
    "* Paper(Arxiv) : https://arxiv.org/abs/1808.01400  \n",
    "* Official Github : https://github.com/tech-srl/code2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cnth1kMQwrNl"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import warnings\n",
    "import logging\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "from torch import einsum\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "from src import utils, messenger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '../configs/config_code2seq.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(config_file), Loader=yaml.FullLoader)\n",
    "\n",
    "# Data source\n",
    "DATA_HOME = config['data']['home']\n",
    "DICT_FILE = DATA_HOME + config['data']['dict']\n",
    "TRAIN_DIR = DATA_HOME + config['data']['train']\n",
    "VALID_DIR = DATA_HOME + config['data']['valid']\n",
    "TEST_DIR  = DATA_HOME + config['data']['test']\n",
    "\n",
    "# Training parameter\n",
    "batch_size = config['training']['batch_size']\n",
    "num_epochs = config['training']['num_epochs']\n",
    "lr = config['training']['lr']\n",
    "teacher_forcing_rate = config['training']['teacher_forcing_rate']\n",
    "nesterov = config['training']['nesterov']\n",
    "weight_decay = config['training']['weight_decay']\n",
    "momentum = config['training']['momentum']\n",
    "decay_ratio = config['training']['decay_ratio']\n",
    "save_name = config['training']['save_name']\n",
    "warm_up = config['training']['warm_up']\n",
    "patience = config['training']['patience']\n",
    "\n",
    "\n",
    "\n",
    "# Model parameter\n",
    "token_size = config['model']['token_size']\n",
    "hidden_size = config['model']['hidden_size']\n",
    "num_layers = config['model']['num_layers']\n",
    "bidirectional = config['model']['bidirectional']\n",
    "rnn_dropout = config['model']['rnn_dropout']\n",
    "embeddings_dropout = config['model']['embeddings_dropout']\n",
    "num_k = config['model']['num_k']\n",
    "\n",
    "# etc\n",
    "slack_url_path = config['etc']['slack_url_path']\n",
    "info_prefix = config['etc']['info_prefix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "slack_url = None\n",
    "if os.path.exists(slack_url_path):\n",
    "    slack_url = yaml.load(open(slack_url_path), Loader=yaml.FullLoader)['slack_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code2seq run_id : 2019-11-10--15-07-07\n",
      "code2seq log_file : ../logs/2019-11-10--15-07-07.log\n",
      "code2seq exp_dir : ../runs/2019-11-10--15-07-07\n",
      "code2seq device : cpu\n",
      "code2seq {'data': {'home': '../data', 'dict': '/java-small/java-small.dict.c2s', 'train': '/java-small/train', 'valid': '/java-small/val', 'test': '/java-small/test'}, 'training': {'batch_size': 256, 'num_epochs': 50, 'lr': 0.001, 'teacher_forcing_rate': 0.4, 'nesterov': True, 'weight_decay': 0.01, 'momentum': 0.95, 'decay_ratio': 0.95, 'save_name': '/model.pth', 'warm_up': 1, 'patience': 2}, 'model': {'token_size': 128, 'hidden_size': 64, 'num_layers': 1, 'bidirectional': True, 'rnn_dropout': 0.5, 'embeddings_dropout': 0.3, 'num_k': 200}, 'etc': {'info_prefix': 'code2seq', 'slack_url_path': '../slack/slack_url.yml'}, 'comment': 'code2seq'}\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(1)\n",
    "random_state = 42\n",
    "\n",
    "run_id = datetime.now().strftime('%Y-%m-%d--%H-%M-%S')\n",
    "log_file = '../logs/' + run_id + '.log'\n",
    "exp_dir = '../runs/' + run_id\n",
    "os.mkdir(exp_dir)\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s | %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p', filename=log_file, level=logging.DEBUG)\n",
    "msgr = messenger.Info(info_prefix, slack_url)\n",
    "\n",
    "msgr.print_msg('run_id : {}'.format(run_id))\n",
    "msgr.print_msg('log_file : {}'.format(log_file))\n",
    "msgr.print_msg('exp_dir : {}'.format(exp_dir))\n",
    "msgr.print_msg('device : {}'.format(device))\n",
    "msgr.print_msg(str(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JM84CUHawrNv"
   },
   "outputs": [],
   "source": [
    "PAD_TOKEN = '<PAD>' \n",
    "BOS_TOKEN = '<S>' \n",
    "EOS_TOKEN = '</S>'\n",
    "UNK_TOKEN = '<UNK>'\n",
    "PAD = 0\n",
    "BOS = 1\n",
    "EOS = 2\n",
    "UNK = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjRMDX0gwrNy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code2seq Dictionaries loaded.\n"
     ]
    }
   ],
   "source": [
    "# load vocab dict\n",
    "with open(DICT_FILE, 'rb') as file:\n",
    "    subtoken_to_count = pickle.load(file)\n",
    "    node_to_count = pickle.load(file) \n",
    "    target_to_count = pickle.load(file)\n",
    "    max_contexts = pickle.load(file)\n",
    "    num_training_examples = pickle.load(file)\n",
    "    msgr.print_msg('Dictionaries loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRqsluoYwrOC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code2seq vocab_size_subtoken：73908\n",
      "code2seq vocab_size_nodes：325\n",
      "code2seq vocab_size_target：11320\n",
      "code2seq num_examples : 691974\n"
     ]
    }
   ],
   "source": [
    "# making vocab dicts for terminal subtoken, nonterminal node and target.\n",
    "\n",
    "word2id = {\n",
    "    PAD_TOKEN: PAD,\n",
    "    BOS_TOKEN: BOS,\n",
    "    EOS_TOKEN: EOS,\n",
    "    UNK_TOKEN: UNK,\n",
    "    }\n",
    "\n",
    "vocab_subtoken = utils.Vocab(word2id=word2id)\n",
    "vocab_nodes = utils.Vocab(word2id=word2id)\n",
    "vocab_target = utils.Vocab(word2id=word2id)\n",
    "\n",
    "vocab_subtoken.build_vocab(list(subtoken_to_count.keys()), min_count=0)\n",
    "vocab_nodes.build_vocab(list(node_to_count.keys()), min_count=0)\n",
    "vocab_target.build_vocab(list(target_to_count.keys()), min_count=0)\n",
    "\n",
    "vocab_size_subtoken = len(vocab_subtoken.id2word)\n",
    "vocab_size_nodes = len(vocab_nodes.id2word)\n",
    "vocab_size_target = len(vocab_target.id2word)\n",
    "\n",
    "\n",
    "msgr.print_msg('vocab_size_subtoken：' + str(vocab_size_subtoken))\n",
    "msgr.print_msg('vocab_size_nodes：' + str(vocab_size_nodes))\n",
    "msgr.print_msg('vocab_size_target：' + str(vocab_size_target))\n",
    "\n",
    "num_length_train = num_training_examples\n",
    "msgr.print_msg('num_examples : ' + str(num_length_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "\n",
    "    def __init__(self, data_path, batch_size, num_k, vocab_subtoken, vocab_nodes, vocab_target, shuffle=True, batch_time = False):\n",
    "        \n",
    "        \"\"\"\n",
    "        data_path : path for data \n",
    "        num_examples : total lines of data file\n",
    "        batch_size : batch size\n",
    "        num_k : max ast pathes included to one examples\n",
    "        vocab_subtoken : dict of subtoken and its id\n",
    "        vocab_nodes : dict of node simbol and its id\n",
    "        vocab_target : dict of target simbol and its id\n",
    "        \"\"\"\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.num_examples = self.file_count(data_path)\n",
    "        self.num_k = num_k\n",
    "        \n",
    "        self.vocab_subtoken = vocab_subtoken\n",
    "        self.vocab_nodes = vocab_nodes\n",
    "        self.vocab_target = vocab_target\n",
    "        \n",
    "        self.index = 0\n",
    "        self.pointer = np.array(range(self.num_examples))\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.batch_time = batch_time\n",
    "        \n",
    "        self.reset()\n",
    "\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        \n",
    "        if self.batch_time:\n",
    "            t1 = time.time()\n",
    "      \n",
    "        if self.index >= self.num_examples:\n",
    "            self.reset()\n",
    "            raise StopIteration()\n",
    "        \n",
    "        ids = self.pointer[self.index: self.index + self.batch_size]\n",
    "        seqs_S, seqs_N, seqs_E, seqs_Y = self.read_batch(ids)\n",
    "        \n",
    "        # length_k : (batch_size, k)\n",
    "        lengths_k = [len(ex) for ex in seqs_N]\n",
    "        \n",
    "        # flattening (batch_size, k, l) to (batch_size * k, l)\n",
    "        # this is useful to make torch.tensor\n",
    "        seqs_S = [symbol for k in seqs_S for symbol in k]\n",
    "        seqs_N = [symbol for k in seqs_N for symbol in k] \n",
    "        seqs_E = [symbol for k in seqs_E for symbol in k] \n",
    "        \n",
    "        # Padding\n",
    "        lengths_S = [len(s) for s in seqs_S]\n",
    "        lengths_N = [len(s) for s in seqs_N]\n",
    "        lengths_E = [len(s) for s in seqs_E]\n",
    "        lengths_Y = [len(s) for s in seqs_Y]\n",
    "        \n",
    "        max_length_S = max(lengths_S)\n",
    "        max_length_N = max(lengths_N)\n",
    "        max_length_E = max(lengths_E)\n",
    "        max_length_Y = max(lengths_Y)\n",
    "\n",
    "        padded_S = [utils.pad_seq(s, max_length_S) for s in seqs_S]\n",
    "        padded_N = [utils.pad_seq(s, max_length_N) for s in seqs_N]\n",
    "        padded_E = [utils.pad_seq(s, max_length_E) for s in seqs_E]\n",
    "        padded_Y = [utils.pad_seq(s, max_length_Y) for s in seqs_Y]\n",
    "        \n",
    "        # index for split (batch_size * k, l) into (batch_size, k, l)\n",
    "        index_N = range(len(lengths_N))\n",
    "        \n",
    "        # sort for rnn\n",
    "        seq_pairs = sorted(zip(lengths_N, index_N, padded_N, padded_S, padded_E), key=lambda p: p[0], reverse=True)\n",
    "        lengths_N, index_N, padded_N, padded_S, padded_E = zip(*seq_pairs)\n",
    "        \n",
    "        batch_S = torch.tensor(padded_S, dtype=torch.long, device=device)\n",
    "        batch_E = torch.tensor(padded_E, dtype=torch.long, device=device)\n",
    "        \n",
    "        # transpose for rnn\n",
    "        batch_N = torch.tensor(padded_N, dtype=torch.long, device=device).transpose(0, 1)\n",
    "        batch_Y = torch.tensor(padded_Y, dtype=torch.long, device=device).transpose(0, 1)\n",
    "        \n",
    "        # update index\n",
    "        self.index += self.batch_size\n",
    "        \n",
    "        if self.batch_time:\n",
    "            t2 = time.time()\n",
    "            elapsed_time = t2-t1\n",
    "            print(f\"batching time：{elapsed_time}\")\n",
    "\n",
    "        return batch_S, batch_N, batch_E, batch_Y, lengths_S, lengths_N, lengths_E, lengths_Y, max_length_S,max_length_N,max_length_E,max_length_Y, lengths_k, index_N\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        if self.shuffle:\n",
    "            self.pointer = shuffle(self.pointer)\n",
    "        self.index = 0 \n",
    "        \n",
    "    def file_count(self, path):\n",
    "        lst = [name for name in os.listdir(path) if os.path.isfile(os.path.join(path, name))]\n",
    "        return len(lst)\n",
    "        \n",
    "    def read_batch(self, ids):\n",
    "        \n",
    "        seqs_S = []\n",
    "        seqs_E = []\n",
    "        seqs_N = []\n",
    "        seqs_Y = []\n",
    "        \n",
    "        for i in ids:\n",
    "            path = self.data_path + '/{:0>6d}.txt'.format(i)\n",
    "            with open(path, 'r') as f:\n",
    "                seq_S = []\n",
    "                seq_N = []\n",
    "                seq_E = []\n",
    "\n",
    "                target, *syntax_path = f.readline().split(' ')\n",
    "                target = target.split('|')\n",
    "                target = utils.sentence_to_ids(self.vocab_target, target)\n",
    "\n",
    "                # remove '' and '\\n' in sequence, java-small dataset contains many '' in a line.\n",
    "                syntax_path = [s for s in syntax_path if s != '' and s != '\\n']\n",
    "\n",
    "                # if the amount of ast path exceed the k,\n",
    "                # uniformly sample ast pathes, as described in the paper.\n",
    "                if len(syntax_path) > self.num_k:\n",
    "                    sampled_path_index = random.sample(range(len(syntax_path)) , self.num_k)\n",
    "                else :\n",
    "                    sampled_path_index = range(len(syntax_path))\n",
    "\n",
    "                for j in sampled_path_index:\n",
    "                    terminal1, ast_path, terminal2 = syntax_path[j].split(',')\n",
    "\n",
    "                    terminal1 = utils.sentence_to_ids(self.vocab_subtoken, terminal1.split('|'))\n",
    "                    ast_path = utils.sentence_to_ids(self.vocab_nodes, ast_path.split('|'))\n",
    "                    terminal2 = utils.sentence_to_ids(self.vocab_subtoken, terminal2.split('|')) \n",
    "\n",
    "                    seq_S.append(terminal1)\n",
    "                    seq_E.append(terminal2)\n",
    "                    seq_N.append(ast_path)\n",
    "\n",
    "                seqs_S.append(seq_S)\n",
    "                seqs_E.append(seq_E)\n",
    "                seqs_N.append(seq_N)\n",
    "                seqs_Y.append(target)\n",
    "\n",
    "        return seqs_S, seqs_N, seqs_E, seqs_Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-7lLgR9WwrPS"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size_subtoken, input_size_node, token_size, hidden_size, bidirectional = True, num_layers = 2, rnn_dropout = 0.5, embeddings_dropout = 0.25):\n",
    "        \n",
    "        \"\"\"\n",
    "        input_size_subtoken : # of unique subtoken\n",
    "        input_size_node : # of unique node symbol\n",
    "        token_size : embedded token size\n",
    "        hidden_size : size of initial state of decoder\n",
    "        rnn_dropout = 0.5 : rnn drop out ratio\n",
    "        embeddings_dropout = 0.25 : dropout ratio for context vector\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.token_size = token_size\n",
    "\n",
    "        self.embedding_subtoken = nn.Embedding(input_size_subtoken, token_size, padding_idx=PAD)\n",
    "        self.embedding_node = nn.Embedding(input_size_node, token_size, padding_idx=PAD)\n",
    "        \n",
    "        self.lstm = nn.LSTM(token_size, token_size, num_layers = num_layers, bidirectional=bidirectional, dropout=rnn_dropout)\n",
    "        self.out = nn.Linear(token_size * 4, hidden_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(embeddings_dropout)\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, batch_S, batch_N, batch_E, lengths_k, index_N, hidden=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        batch_S : (B * k, l) start terminals' subtoken of each ast path\n",
    "        batch_N : (l, B*k) nonterminals' nodes of each ast path\n",
    "        batch_E : (B * k, l) end terminals' subtoken of each ast path\n",
    "        \n",
    "        lengths_k : length of k in each example\n",
    "        index_N : index for unsorting,\n",
    "        \"\"\"\n",
    "        \n",
    "        bk_size = batch_N.shape[1]\n",
    "        output_bag = []\n",
    "        hidden_batch = []\n",
    "        \n",
    "        # (B * k, l, d)\n",
    "        encode_S = self.embedding_subtoken(batch_S)\n",
    "        encode_E = self.embedding_subtoken(batch_E)\n",
    "        \n",
    "        # encode_S (B * k, d) token_representation of each ast path\n",
    "        encode_S = encode_S.sum(1)\n",
    "        encode_E = encode_E.sum(1)\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        LSTM Outputs: output, (h_n, c_n)\n",
    "        output (seq_len, batch, num_directions * hidden_size)\n",
    "        h_n    (num_layers * num_directions, batch, hidden_size) : tensor containing the hidden state for t = seq_len.\n",
    "        c_n    (num_layers * num_directions, batch, hidden_size)\n",
    "        \"\"\"\n",
    "        \n",
    "        # emb_N :(l, B*k, d)\n",
    "        emb_N = self.embedding_node(batch_N)\n",
    "        packed = pack_padded_sequence(emb_N, lengths_N)\n",
    "        output, (hidden, cell) = self.lstm(packed, hidden)\n",
    "        #output, _ = pad_packed_sequence(output)\n",
    "        \n",
    "        # hidden (num_layers * num_directions, batch, hidden_size)\n",
    "        # only last layer, (num_directions, batch, hidden_size)\n",
    "        hidden = hidden[-self.num_directions:, :, :]\n",
    "        \n",
    "        # -> (Bk, num_directions, hidden_size)\n",
    "        hidden = hidden.transpose(0, 1)\n",
    "        \n",
    "        # -> (Bk, 1, hidden_size * num_directions)\n",
    "        hidden = hidden.contiguous().view(bk_size, 1, -1)\n",
    "        \n",
    "        # encode_N (Bk, hidden_size * num_directions)\n",
    "        encode_N = hidden.squeeze(1)\n",
    "        \n",
    "        # encode_SNE  : (B*k, hidden_size * num_directions + 2)\n",
    "        encode_SNE = torch.cat([encode_N, encode_S, encode_E], dim=1)\n",
    "        \n",
    "        # encode_SNE  : (B*k, d)\n",
    "        encode_SNE = self.out(encode_SNE)\n",
    "        \n",
    "        # unsort as example\n",
    "        #index = torch.tensor(index_N, dtype=torch.long, device=device)\n",
    "        #encode_SNE = torch.index_select(encode_SNE, dim=0, index=index)\n",
    "        index = np.argsort(index_N)\n",
    "        encode_SNE = encode_SNE[[index]]\n",
    "        \n",
    "        # as is in  https://github.com/tech-srl/code2seq/blob/ec0ae309efba815a6ee8af88301479888b20daa9/model.py#L511\n",
    "        encode_SNE = self.dropout(encode_SNE)\n",
    "        \n",
    "        # output_bag  : [ B, (k, d) ]\n",
    "        output_bag = torch.split(encode_SNE, lengths_k, dim=0)\n",
    "        \n",
    "        # hidden_0  : (1, B, d)\n",
    "        # for decoder initial state\n",
    "        hidden_0 = [ob.mean(0).unsqueeze(dim=0) for ob in output_bag]\n",
    "        hidden_0 = torch.cat(hidden_0, dim=0).unsqueeze(dim=0)\n",
    "        \n",
    "        return output_bag, hidden_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "flU2AatIwrPl"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, rnn_dropout):\n",
    "        \"\"\"\n",
    "        hidden_size : decoder unit size, \n",
    "        output_size : decoder output size, \n",
    "        rnn_dropout : dropout ratio for rnn\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=PAD)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, dropout=rnn_dropout)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, seqs, hidden, attn):\n",
    "        emb = self.embedding(seqs)\n",
    "        _, hidden = self.gru(emb, hidden)\n",
    "        \n",
    "        output = torch.cat((hidden, attn), 2)\n",
    "        output = self.out(output)\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XCPLR4MkQ_U1"
   },
   "source": [
    "#### Attention\n",
    "\n",
    "$$\n",
    "   \\alpha ^ t = softmax(h_t W_a z).\n",
    "$$\n",
    "\n",
    "$$\n",
    "    c_t = {\\sum^n_{i} \\alpha_i^tz_i} .\n",
    "$$\n",
    "\n",
    "$$\n",
    "    y_t = \\mathrm{softmax}(W_{s} \\mathrm{tanh} (W_{c} [c_t:h_t] )   )\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zsuAuSteQ_U3"
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder_with_Attention(nn.Module):\n",
    "    \n",
    "    \"\"\"Conbine Encoder and Decoder\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size_subtoken, input_size_node, token_size, output_size, hidden_size, bidirectional = True, num_layers = 2, rnn_dropout = 0.5, embeddings_dropout = 0.25):\n",
    "\n",
    "        super(EncoderDecoder_with_Attention, self).__init__()\n",
    "        self.encoder = Encoder(input_size_subtoken, input_size_node, token_size, hidden_size, bidirectional = bidirectional, num_layers = num_layers, rnn_dropout = rnn_dropout, embeddings_dropout = embeddings_dropout)\n",
    "        self.decoder = Decoder(hidden_size, output_size, rnn_dropout)\n",
    "        \n",
    "        self.W_a  = torch.rand((hidden_size, hidden_size), dtype=torch.float,device=device , requires_grad=True)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.W_a)\n",
    "        \n",
    "        \n",
    "    def forward(self, batch_S, batch_N, batch_E, lengths_S, lengths_N, lengths_E, lengths_Y, max_length_S, max_length_N,max_length_E,max_length_Y, lengths_k, index_N, terget_max_length, batch_Y=None, use_teacher_forcing=False):\n",
    "\n",
    "        # Encoder\n",
    "        encoder_output_bag, encoder_hidden = \\\n",
    "          self.encoder(batch_S, batch_N, batch_E, lengths_k, index_N)\n",
    "        \n",
    "        _batch_size = len(encoder_output_bag)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        # make initial input for decoder\n",
    "        decoder_input = torch.tensor([BOS] * _batch_size, dtype=torch.long, device=device)\n",
    "        decoder_input = decoder_input.unsqueeze(0)  # (1, batch_size)\n",
    "        \n",
    "        # output holder\n",
    "        decoder_outputs = torch.zeros(terget_max_length, _batch_size, self.decoder.output_size, device=device)\n",
    "        \n",
    "        #print('=' * 20)\n",
    "        for t in range(terget_max_length):\n",
    "            \n",
    "            # ct\n",
    "            ct = self.attention(encoder_output_bag, decoder_hidden, lengths_k)\n",
    "            \n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, ct)\n",
    "            \n",
    "            #print(decoder_output.max(-1)[1])\n",
    "            \n",
    "            decoder_outputs[t] = decoder_output\n",
    "            \n",
    "            # Teacher Forcing\n",
    "            if use_teacher_forcing and batch_Y is not None:\n",
    "                decoder_input = batch_Y[t].unsqueeze(0)\n",
    "            else: \n",
    "                decoder_input = decoder_output.max(-1)[1]\n",
    "        \n",
    "        return decoder_outputs\n",
    "    \n",
    "    def attention(self, encoder_output_bag, hidden, lengths_k):\n",
    "        \n",
    "        \"\"\"\n",
    "        encoder_output_bag : (batch, k, hidden_size) bag of embedded ast path\n",
    "        hidden : (1 , batch, hidden_size):\n",
    "        lengths_k : (batch, 1) length of k in each example\n",
    "        \"\"\"\n",
    "        \n",
    "        # e_out : (batch * k, hidden_size)\n",
    "        e_out = torch.cat(encoder_output_bag, dim=0)\n",
    "        \n",
    "        # e_out : (batch * k(i), hidden_size(j))\n",
    "        # self.W_a  : [hidden_size(j), hidden_size(k)]\n",
    "        # ha -> : [batch * k(i), hidden_size(k)]\n",
    "        ha = einsum('ij,jk->ik', e_out, self.W_a)\n",
    "        \n",
    "        # ha -> : [batch, (k, hidden_size)]\n",
    "        ha = torch.split(ha, lengths_k, dim=0)\n",
    "        \n",
    "        # dh = [batch, (1, hidden_size)]\n",
    "        hd = hidden.transpose(0,1)\n",
    "        hd = torch.unbind(hd, dim = 0)\n",
    "        \n",
    "        # _ha : (k(i), hidden_size(j))\n",
    "        # _hd : (1(k), hidden_size(j))\n",
    "        # at : [batch, ( k(i) ) ]\n",
    "        at = [F.softmax(torch.einsum('ij,kj->i', _ha, _hd), dim=0) for _ha, _hd in zip(ha, hd)]\n",
    "        \n",
    "        # a : ( k(i) )\n",
    "        # e : ( k(i), hidden_size(j))\n",
    "        # ct : [batch, (hidden_size(j)) ] -> [batch, (1, hidden_size) ]\n",
    "        ct = [torch.einsum('i,ij->j', a, e).unsqueeze(0) for a, e in zip(at, encoder_output_bag)]\n",
    "        \n",
    "        # ct [batch, hidden_size(k)]\n",
    "        # -> (1, batch, hidden_size)\n",
    "        ct = torch.cat(ct, dim=0).unsqueeze(0)\n",
    "        \n",
    "        \n",
    "        return ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqnxqyXqwrP0"
   },
   "outputs": [],
   "source": [
    "mce = nn.CrossEntropyLoss(size_average=False, ignore_index=PAD)\n",
    "def masked_cross_entropy(logits, target):\n",
    "    return mce(logits.view(-1, logits.size(-1)), target.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7kp7px_O7-1J"
   },
   "outputs": [],
   "source": [
    "batch_time = False\n",
    "train_dataloader = DataLoader(TRAIN_DIR, batch_size, num_k, vocab_subtoken, vocab_nodes, vocab_target, batch_time=batch_time, shuffle=True)\n",
    "valid_dataloader = DataLoader(VALID_DIR, batch_size, num_k, vocab_subtoken, vocab_nodes, vocab_target, shuffle=False)\n",
    "\n",
    "model_args = {\n",
    "    'input_size_subtoken' : vocab_size_subtoken,\n",
    "    'input_size_node' : vocab_size_nodes,\n",
    "    'output_size' : vocab_size_target,\n",
    "    'hidden_size' : hidden_size, \n",
    "    'token_size' : token_size,\n",
    "    'bidirectional' : bidirectional,\n",
    "    'num_layers' : num_layers,\n",
    "    'rnn_dropout' : rnn_dropout, \n",
    "    'embeddings_dropout' : embeddings_dropout\n",
    "}\n",
    "\n",
    "model = EncoderDecoder_with_Attention(**model_args).to(device)\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum, nesterov = nesterov)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda epoch: decay_ratio ** epoch)\n",
    "\n",
    "fname = exp_dir + save_name\n",
    "early_stopping = utils.EarlyStopping(fname, patience, warm_up, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IujU0wrrwrQE"
   },
   "outputs": [],
   "source": [
    "def compute_loss(batch_S, batch_N, batch_E, batch_Y, lengths_S, lengths_N, lengths_E, lengths_Y, max_length_S,max_length_N,max_length_E,max_length_Y, lengths_k, index_N, model, optimizer=None, is_train=True):\n",
    "    model.train(is_train)\n",
    "    \n",
    "    use_teacher_forcing = is_train and (random.random() < teacher_forcing_rate)\n",
    "    \n",
    "    target_max_length = batch_Y.size(0)\n",
    "    pred_Y = model(batch_S, batch_N, batch_E, lengths_S, lengths_N, lengths_E, lengths_Y, max_length_S,max_length_N,max_length_E,max_length_Y, lengths_k, index_N, target_max_length, batch_Y, use_teacher_forcing)\n",
    "    \n",
    "    loss = masked_cross_entropy(pred_Y.contiguous(), batch_Y.contiguous())\n",
    "    \n",
    "    if is_train:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    batch_Y = batch_Y.transpose(0, 1).contiguous().data.cpu().tolist()\n",
    "    pred = pred_Y.max(dim=-1)[1].data.cpu().numpy().T.tolist()\n",
    "    \n",
    "    \n",
    "    return loss.item(), batch_Y, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nTCOrAinwrQQ"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3cbb936be148a6be63c3a141251379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='TRAIN', max=2704, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5664bf0e19c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mmax_length_S\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_length_N\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_length_E\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_length_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mlengths_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-e4f9ab8d59c5>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(batch_S, batch_N, batch_E, batch_Y, lengths_S, lengths_N, lengths_E, lengths_Y, max_length_S, max_length_N, max_length_E, max_length_Y, lengths_k, index_N, model, optimizer, is_train)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#\n",
    "# Training Loop\n",
    "# \n",
    "progress_bar = False # progress bar is visible in progress_bar = False\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train_loss = 0.\n",
    "    train_refs = []\n",
    "    train_hyps = []\n",
    "    valid_loss = 0.\n",
    "    valid_refs = []\n",
    "    valid_hyps = []\n",
    "    \n",
    "    # train\n",
    "    for batch in tqdm(train_dataloader, total=train_dataloader.num_examples // train_dataloader.batch_size + 1, desc='TRAIN'):\n",
    "        batch_S, batch_N, batch_E, batch_Y, lengths_S, lengths_N, lengths_E, lengths_Y, max_length_S, max_length_N,max_length_E,max_length_Y, lengths_k, index_N = batch\n",
    "        \n",
    "        loss, gold, pred = compute_loss(\n",
    "            batch_S, batch_N, batch_E, batch_Y, \n",
    "            lengths_S, lengths_N, lengths_E, lengths_Y, \n",
    "            max_length_S,max_length_N,max_length_E,max_length_Y, \n",
    "            lengths_k, index_N, model, optimizer,\n",
    "            is_train=True\n",
    "            )\n",
    "        \n",
    "        train_loss += loss\n",
    "        train_refs += gold\n",
    "        train_hyps += pred\n",
    "    \n",
    "    # valid\n",
    "    for batch in tqdm(valid_dataloader, total=valid_dataloader.num_examples // valid_dataloader.batch_size + 1, desc='VALID'):\n",
    "\n",
    "        batch_S, batch_N, batch_E, batch_Y, lengths_S, lengths_N, lengths_E, lengths_Y, max_length_S,max_length_N,max_length_E,max_length_Y, lengths_k, index_N = batch\n",
    "\n",
    "        loss, gold, pred = compute_loss(\n",
    "            batch_S, batch_N, batch_E, batch_Y, \n",
    "            lengths_S, lengths_N, lengths_E, lengths_Y, \n",
    "            max_length_S,max_length_N,max_length_E,max_length_Y, \n",
    "            lengths_k, index_N, model, optimizer,\n",
    "            is_train=False\n",
    "            )\n",
    "        \n",
    "        valid_loss += loss\n",
    "        valid_refs += gold\n",
    "        valid_hyps += pred\n",
    "            \n",
    "\n",
    "    train_loss = np.sum(train_loss) / train_dataloader.num_examples\n",
    "    valid_loss = np.sum(valid_loss) / valid_dataloader.num_examples\n",
    "    \n",
    "    # F1 etc\n",
    "    train_precision, train_recall, train_f1 = utils.calculate_results_set(train_refs, train_hyps)\n",
    "    valid_precision, valid_recall, valid_f1 = utils.calculate_results_set(valid_refs, valid_hyps)\n",
    "\n",
    "    \n",
    "    early_stopping(valid_f1, model, epoch)\n",
    "    if early_stopping.early_stop:\n",
    "        msgr.print_msg(\"Early stopping\")\n",
    "        break\n",
    "    \n",
    "    msgr.print_msg('Epoch {}: train_loss: {:5.2f}  train_f1: {:2.4f}  valid_loss: {:5.2f}  valid_f1: {:2.4f}'.format(\n",
    "            epoch, train_loss, train_f1, valid_loss, valid_f1))\n",
    "    \n",
    "    print('-'*80)\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QsQay14VEwYJ"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "swYlOn13Q_VU"
   },
   "outputs": [],
   "source": [
    "model = EncoderDecoder_with_Attention(**model_args).to(device)\n",
    "\n",
    "fname = exp_dir + save_name\n",
    "ckpt = torch.load(fname)\n",
    "model.load_state_dict(ckpt)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2GKrKzSDQ_VW"
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(TEST_DIR, batch_size, num_k, vocab_subtoken, vocab_nodes, vocab_target, batch_time=batch_time, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lY6ty-rNG76n"
   },
   "outputs": [],
   "source": [
    "refs_list = []\n",
    "hyp_list = []\n",
    "\n",
    "for batch in tqdm(test_dataloader,\n",
    "                      total=test_dataloader.num_examples // test_dataloader.batch_size + 1,\n",
    "                      desc='TEST'):\n",
    "    \n",
    "    batch_S, batch_N, batch_E, batch_Y, lengths_S, lengths_N, lengths_E, lengths_Y, max_length_S,max_length_N,max_length_E,max_length_Y, lengths_k, index_N = batch\n",
    "    target_max_length = batch_Y.size(0)\n",
    "    use_teacher_forcing = False\n",
    "    \n",
    "    pred_Y = model(batch_S, batch_N, batch_E, lengths_S, lengths_N, lengths_E, lengths_Y, max_length_S,max_length_N,max_length_E,max_length_Y, lengths_k, index_N, target_max_length, batch_Y, use_teacher_forcing)\n",
    "    \n",
    "    refs = batch_Y.transpose(0, 1).contiguous().data.cpu().tolist()[0]\n",
    "    pred = pred_Y.max(dim=-1)[1].data.cpu().numpy().T.tolist()[0]\n",
    "    \n",
    "    refs_list.append(refs)\n",
    "    hyp_list.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVDf6TOAPE8z"
   },
   "outputs": [],
   "source": [
    "msgr.print_msg('Tested model : ' + fname)\n",
    "\n",
    "test_precision, test_recall, test_f1 = utils.calculate_results(refs_list, hyp_list)\n",
    "msgr.print_msg('Test : precision {:1.5f}, recall {:1.5f}, f1 {:1.5f}'.format(test_precision, test_recall, test_f1))\n",
    "\n",
    "test_precision, test_recall, test_f1 = utils.calculate_results_set(refs_list, hyp_list)\n",
    "msgr.print_msg('Test(set) : precision {:1.5f}, recall {:1.5f}, f1 {:1.5f}'.format(test_precision, test_recall, test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_time = False\n",
    "test_dataloader = DataLoader(TEST_DIR, 1, num_k, vocab_subtoken, vocab_nodes, vocab_target, batch_time=batch_time, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "batch_S, batch_N, batch_E, batch_Y, lengths_S, lengths_N, lengths_E, lengths_Y, max_length_S,max_length_N,max_length_E,max_length_Y, lengths_k, index_N = next(test_dataloader)\n",
    "\n",
    "sentence_Y = ' '.join(utils.ids_to_sentence(vocab_target, batch_Y.data.cpu().numpy()[:-1, 0]))\n",
    "msgr.print_msg('tgt: {}'.format(sentence_Y))\n",
    "\n",
    "target_max_length = batch_Y.size(0)\n",
    "use_teacher_forcing = False\n",
    "output = model(batch_S, batch_N, batch_E, lengths_S, lengths_N, lengths_E, lengths_Y, max_length_S,max_length_N,max_length_E,max_length_Y, lengths_k, index_N, target_max_length, batch_Y, use_teacher_forcing)\n",
    "\n",
    "output = output.max(dim=-1)[1].view(-1).data.cpu().tolist()\n",
    "output_sentence = ' '.join(utils.ids_to_sentence(vocab_target, utils.trim_eos(output)))\n",
    "msgr.print_msg('out: {}'.format(output_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "code2seq.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
